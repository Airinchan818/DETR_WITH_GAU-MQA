{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u9JPQTqdIkPz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from scipy.optimize import linear_sum_assignment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GatingAttentionUnit (nn.Module) :\n",
        "  def __init__ (self,embed_dim) :\n",
        "    super().__init__()\n",
        "    self.lq = nn.Linear(embed_dim,embed_dim,bias=False)\n",
        "    self.lk = nn.Linear(embed_dim,embed_dim,bias=False)\n",
        "    self.lv = nn.Linear(embed_dim,embed_dim,bias=False)\n",
        "    self.lgate = nn.Linear(embed_dim,embed_dim)\n",
        "    self.lo = nn.Linear(embed_dim,embed_dim)\n",
        "\n",
        "  def __countAttention (self,Q,K,V) :\n",
        "    score = torch.matmul(Q,K.transpose(-2,-1)) / K.shape[-1] ** 0.5\n",
        "    attention = F.softplus(score)\n",
        "    output = torch.matmul(attention,V)\n",
        "    return output\n",
        "\n",
        "  def forward(self,Q,K,V) :\n",
        "    q = self.lq(Q)\n",
        "    k = self.lk(K)\n",
        "    v = self.lv(V)\n",
        "    attention = self.__countAttention(q,k,v)\n",
        "    gate = self.lgate(Q)\n",
        "    gate = F.sigmoid(gate)\n",
        "    output = attention * gate\n",
        "    output = self.lo(output)\n",
        "    return output\n",
        "\n",
        "class MultiQueryAttention (nn.Module) :\n",
        "  def __init__ (self,embed_dim,num_queary) :\n",
        "    super().__init__()\n",
        "    self.query_dim = embed_dim // num_queary\n",
        "    self.num_q = num_queary\n",
        "    self.lq = nn.Linear(embed_dim,embed_dim,bias=False)\n",
        "    self.lk = nn.Linear(embed_dim,self.query_dim,bias=False)\n",
        "    self.lv = nn.Linear(embed_dim,self.query_dim,bias=False)\n",
        "    self.lo = nn.Linear(embed_dim,embed_dim)\n",
        "\n",
        "  def __split_heads(self,x : torch.Tensor) :\n",
        "    b,s,d = x.shape\n",
        "    x = x.reshape(b,s,self.num_q,self.query_dim)\n",
        "    return x.transpose(1,2)\n",
        "\n",
        "  def __scaled_dot_product(self,Q,K,V) :\n",
        "    score = torch.matmul(Q,K.transpose(-2,-1)) / K.shape[-1] ** 0.5\n",
        "    attention = F.softmax(score,dim=-1)\n",
        "    output = torch.matmul(attention,V)\n",
        "    return output\n",
        "\n",
        "  def forward (self,Q,K,V) :\n",
        "    b,s,d = Q.shape\n",
        "    q = self.__split_heads(self.lq(Q))\n",
        "    k = self.lk(K)\n",
        "    k = torch.unsqueeze(k,dim=1)\n",
        "    v = self.lv(V)\n",
        "    v = torch.unsqueeze(v,dim=1)\n",
        "\n",
        "    attn = self.__scaled_dot_product(q,k,v)\n",
        "    attn = torch.permute(attn,(0,2,1,3))\n",
        "    attn = torch.reshape(attn,(b,s,d))\n",
        "    out = self.lo(attn)\n",
        "\n",
        "    return out\n",
        "\n",
        "class ReZero (nn.Module) :\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.alpha = nn.Parameter(torch.zeros(size=(1,)))\n",
        "\n",
        "  def forward(self,x,factor) :\n",
        "    return x + self.alpha * factor\n",
        "\n",
        "class ScaleNorm (nn.Module) :\n",
        "  def __init__(self,embed_dim,epsilon=1e-5) :\n",
        "    super().__init__()\n",
        "    self.gamma = nn.Parameter(torch.ones(size=(embed_dim,)))\n",
        "    self.eps = epsilon\n",
        "\n",
        "  def forward (self,x) :\n",
        "    sum_val = torch.sum(x ** 2,dim=-1,keepdim=True)\n",
        "    norm = torch.sqrt(sum_val) + self.eps\n",
        "    return (x / norm) * self.gamma\n",
        "\n",
        "class LCM (nn.Module) :\n",
        "  def __init__ (self,embed_dim,drop_rate) :\n",
        "    super().__init__()\n",
        "    self.norm = ScaleNorm(embed_dim)\n",
        "    self.dropout = nn.Dropout(p=drop_rate)\n",
        "    self.step1 = nn.Linear(embed_dim,embed_dim)\n",
        "    self.step2 = nn.Linear(embed_dim,embed_dim)\n",
        "    self.magnitude = nn.Linear(embed_dim,embed_dim)\n",
        "    self.rezero = ReZero()\n",
        "\n",
        "\n",
        "  def forward(self,x) :\n",
        "    z = self.norm(x)\n",
        "    step1 = self.step1(z)\n",
        "    step1 = F.gelu(step1,approximate='tanh')\n",
        "    step2 = self.step2(z)\n",
        "    step2 = F.gelu(step2,approximate='tanh')\n",
        "    latent = step1 + step2\n",
        "    latent = self.dropout(latent)\n",
        "    latent = self.magnitude(latent)\n",
        "    latent = F.tanh(latent)\n",
        "    return self.rezero(x,latent)\n",
        "\n",
        "class SiGLU (nn.Module) :\n",
        "  def __init__ (self,embed_dim,hidden_state) :\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(embed_dim,hidden_state)\n",
        "    self.l2 = nn.Linear(embed_dim,hidden_state)\n",
        "    self.l3 = nn.Linear(hidden_state,embed_dim)\n",
        "\n",
        "  def forward (self,x) :\n",
        "    x1 = self.l1(x)\n",
        "    x2 = self.l2(x)\n",
        "    x = x1 * F.silu(x2)\n",
        "    x = self.l3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "95N2U7qeNTdy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding (nn.Module) :\n",
        "  def __init__ (self,image_size,num_patch,embed_dim) :\n",
        "    super().__init__()\n",
        "    self.projection = nn.Conv2d(3,embed_dim,kernel_size=num_patch,stride=num_patch)\n",
        "    self.n_path = (image_size//num_patch)**2\n",
        "\n",
        "  def forward (self,x) :\n",
        "    x = self.projection(x)\n",
        "    x = x.flatten(2)\n",
        "    x = x.transpose(1,2)\n",
        "    return x\n",
        "\n",
        "class PositionalEncoding (nn.Module) :\n",
        "  def __init__ (self,embed_dim,n_path) :\n",
        "    super().__init__()\n",
        "    self.poslearn = nn.Parameter(data=torch.normal(mean=0,std=0.02,size=(1,n_path,embed_dim)))\n",
        "\n",
        "  def forward (self,x) :\n",
        "    return x+self.poslearn\n",
        "\n",
        "class VITBlock (nn.Module) :\n",
        "  def __init__ (self,embed_dim,drop_rate) :\n",
        "    super().__init__()\n",
        "    self.norm = ScaleNorm(embed_dim)\n",
        "    self.dropout = nn.Dropout(p=drop_rate)\n",
        "    self.attention = GatingAttentionUnit(embed_dim)\n",
        "    self.lcm = LCM(embed_dim,drop_rate)\n",
        "    self.rezero = ReZero()\n",
        "\n",
        "  def forward(self,x) :\n",
        "    znorm = self.norm(x)\n",
        "    attn = self.attention(znorm,znorm,znorm)\n",
        "    attn = self.dropout(attn)\n",
        "    x = self.rezero(x,attn)\n",
        "\n",
        "    x = self.lcm(x)\n",
        "    return x\n",
        "\n",
        "class DecoderBlock(nn.Module) :\n",
        "  def __init__(self,embed_dim,drop_rate) :\n",
        "    super().__init__()\n",
        "    self.norm1 = nn.RMSNorm(embed_dim)\n",
        "    self.norm2 = nn.RMSNorm(embed_dim)\n",
        "    self.norm3 = nn.RMSNorm(embed_dim)\n",
        "    self.attention = MultiQueryAttention(embed_dim,num_queary=4)\n",
        "    self.siglu = SiGLU(embed_dim=embed_dim,hidden_state=embed_dim * 2)\n",
        "    self.crossAttention = MultiQueryAttention(embed_dim,num_queary=4)\n",
        "    self.dropou1 = nn.Dropout(p=drop_rate)\n",
        "    self.dropou2 = nn.Dropout(p=drop_rate)\n",
        "    self.dropou3 = nn.Dropout(p=drop_rate)\n",
        "\n",
        "  def forward(self,logits,factor) :\n",
        "    lnorm = self.norm1(logits)\n",
        "    attn = self.attention(lnorm,lnorm,lnorm)\n",
        "    attn =self.dropou1(attn)\n",
        "    logits = logits + attn\n",
        "\n",
        "    lnorm = self.norm2(logits)\n",
        "    attn = self.crossAttention(lnorm,factor,factor)\n",
        "    attn = self.dropou2(attn)\n",
        "    logits = logits + attn\n",
        "\n",
        "    lnorm = self.norm3(logits)\n",
        "    siglu = self.siglu(lnorm)\n",
        "    siglu = self.dropou3(siglu)\n",
        "    logits = logits + siglu\n",
        "    return logits"
      ],
      "metadata": {
        "id": "t4-pRrPwJN5L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VIT (nn.Module) :\n",
        "  def __init__ (self,image_size,patch_size,embed_dim) :\n",
        "    super().__init__()\n",
        "    self.patchembedding = PatchEmbedding(image_size,num_patch=patch_size,embed_dim = embed_dim)\n",
        "    self.postionalencoder = PositionalEncoding(embed_dim,self.patchembedding.n_path)\n",
        "    self.Transformersblock = nn.ModuleList([VITBlock(embed_dim,drop_rate=0.05) for _ in range(3)])\n",
        "    self.globalffn = nn.Sequential(\n",
        "        nn.Linear(embed_dim,embed_dim * 3),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(embed_dim * 3,embed_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self,x) :\n",
        "    x = self.patchembedding(x)\n",
        "    x = self.postionalencoder(x)\n",
        "    for layer in self.Transformersblock :\n",
        "      x = layer(x)\n",
        "    x = self.globalffn(x)\n",
        "    return x\n",
        "\n",
        "class Decoder (nn.Module) :\n",
        "  def __init__(self,embed_dim) :\n",
        "    super().__init__()\n",
        "    self.Decoderblock = nn.ModuleList([DecoderBlock(embed_dim,0.1) for _ in range(3)])\n",
        "\n",
        "  def forward(self,query,memory) :\n",
        "    for layer in self.Decoderblock :\n",
        "      query = layer(query,memory)\n",
        "\n",
        "    return query\n",
        "\n",
        "class DETR (nn.Module) :\n",
        "  def __init__(self,\n",
        "               image_size = 244,embed_dim=512,num_query=100,num_class=1) :\n",
        "               super().__init__()\n",
        "               self.backbone = VIT(image_size=image_size,patch_size=16,embed_dim=embed_dim)\n",
        "               self.object_query = nn.Parameter(torch.randn(size=(num_query,embed_dim)))\n",
        "               self.decoder = Decoder(embed_dim)\n",
        "               self.class_head = nn.Linear(embed_dim,num_class + 1)\n",
        "               self.box_head = nn.Sequential(\n",
        "                   nn.Linear(embed_dim,embed_dim),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Linear(embed_dim,4)\n",
        "               )\n",
        "\n",
        "  def forward(self,x) :\n",
        "    B = x.shape[0]\n",
        "    memory = self.backbone(x)\n",
        "    query = self.object_query.unsqueeze(0).repeat(B,1,1)\n",
        "    query = self.decoder(query,memory)\n",
        "    class_pred = self.class_head(query)\n",
        "    box_pred = self.box_head(query).sigmoid()\n",
        "\n",
        "    return {\n",
        "        'class_pred' : class_pred,\n",
        "        'box_pred' : box_pred\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "xjNaSN2D5Jya"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hungarian_matching(logits, boxes, tgt_labels, tgt_boxes):\n",
        "    \"\"\"\n",
        "    logits: (Q, C)\n",
        "    boxes: (Q, 4)  in cx,cy,w,h normalized\n",
        "    tgt_labels: (T,)\n",
        "    tgt_boxes: (T, 4)\n",
        "    \"\"\"\n",
        "    prob = logits.softmax(-1)\n",
        "    cost_class = -prob[:, tgt_labels]              # (Q, T)\n",
        "    cost_bbox = torch.cdist(boxes, tgt_boxes, p=1) # (Q, T)\n",
        "\n",
        "    cost = cost_class + cost_bbox\n",
        "    cost = cost.detach().cpu()\n",
        "\n",
        "    row_ind, col_ind = linear_sum_assignment(cost)\n",
        "    return row_ind, col_ind\n",
        "\n",
        "\n",
        "def detr_loss(class_pred, box_pred, class_label, box_label, num_classes):\n",
        "    \"\"\"\n",
        "    class_pred: (B, Q, C)\n",
        "    box_pred:   (B, Q, 4)\n",
        "    class_label:(B, T)\n",
        "    box_label:  (B, T, 4)\n",
        "    \"\"\"\n",
        "    loss_cls = 0.\n",
        "    loss_box = 0.\n",
        "\n",
        "    B, Q, _ = class_pred.shape\n",
        "    weight_no_class = torch.ones(num_classes + 1, device=class_pred.device)\n",
        "    weight_no_class[num_classes] = 0.1\n",
        "\n",
        "    for b in range(B):\n",
        "        logits = class_pred[b]\n",
        "        boxes = box_pred[b]\n",
        "        labels = class_label[b]\n",
        "        tgt_boxes = box_label[b]\n",
        "\n",
        "        idx_q, idx_t = hungarian_matching(\n",
        "            logits, boxes, labels, tgt_boxes\n",
        "        )\n",
        "\n",
        "        target_cls = torch.full(\n",
        "            (Q,), num_classes, device=logits.device\n",
        "        )\n",
        "        target_cls[idx_q] = labels[idx_t]\n",
        "\n",
        "        loss_cls += F.cross_entropy(logits, target_cls,weight=weight_no_class)\n",
        "        loss_box += F.l1_loss(boxes[idx_q], tgt_boxes[idx_t])\n",
        "\n",
        "    return loss_cls + loss_box\n"
      ],
      "metadata": {
        "id": "Z3j55ea_gwgJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"adilshamim8/people-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-SCJObsvJsb",
        "outputId": "551c74b8-b743-4f67-ee45-1aab5a84b621"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/adilshamim8/people-detection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.94G/1.94G [00:21<00:00, 95.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/adilshamim8/people-detection/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "QvYRLQ22zixt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path+'/train/train/_annotations.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7wj_pBBFz9JU",
        "outputId": "3db8c1ea-e81b-475f-b5d2-7405e16c6de9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 filename  width  height  \\\n",
              "0       2008_003132_jpg.rf.92f6223defec4f57f2d7b9cfa28...    500     375   \n",
              "1       2008_003132_jpg.rf.92f6223defec4f57f2d7b9cfa28...    500     375   \n",
              "2       2008_003132_jpg.rf.92f6223defec4f57f2d7b9cfa28...    500     375   \n",
              "3       004574_jpg.rf.7c8cea69d7be45f58febcede26ef0c6e...    500     333   \n",
              "4       004574_jpg.rf.7c8cea69d7be45f58febcede26ef0c6e...    500     333   \n",
              "...                                                   ...    ...     ...   \n",
              "100077  2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...   4410    3308   \n",
              "100078  2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...   4410    3308   \n",
              "100079  2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...   4410    3308   \n",
              "100080  2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...   4410    3308   \n",
              "100081  2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...   4410    3308   \n",
              "\n",
              "         class  xmin  ymin  xmax  ymax  \n",
              "0       person   219    98   269   283  \n",
              "1       person   114   124   155   263  \n",
              "2       person    43   139    98   340  \n",
              "3       person   145   118   229   333  \n",
              "4       person   285   105   349   329  \n",
              "...        ...   ...   ...   ...   ...  \n",
              "100077  person  1957  1753  2022  1847  \n",
              "100078  person  2014  1753  2099  1854  \n",
              "100079  person  1519  1805  1588  1920  \n",
              "100080  person  1588  1809  1657  1901  \n",
              "100081  person  1464  1753  1529  1870  \n",
              "\n",
              "[100082 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e32a119-3e62-4875-9c22-c6593fe97b29\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008_003132_jpg.rf.92f6223defec4f57f2d7b9cfa28...</td>\n",
              "      <td>500</td>\n",
              "      <td>375</td>\n",
              "      <td>person</td>\n",
              "      <td>219</td>\n",
              "      <td>98</td>\n",
              "      <td>269</td>\n",
              "      <td>283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008_003132_jpg.rf.92f6223defec4f57f2d7b9cfa28...</td>\n",
              "      <td>500</td>\n",
              "      <td>375</td>\n",
              "      <td>person</td>\n",
              "      <td>114</td>\n",
              "      <td>124</td>\n",
              "      <td>155</td>\n",
              "      <td>263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008_003132_jpg.rf.92f6223defec4f57f2d7b9cfa28...</td>\n",
              "      <td>500</td>\n",
              "      <td>375</td>\n",
              "      <td>person</td>\n",
              "      <td>43</td>\n",
              "      <td>139</td>\n",
              "      <td>98</td>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004574_jpg.rf.7c8cea69d7be45f58febcede26ef0c6e...</td>\n",
              "      <td>500</td>\n",
              "      <td>333</td>\n",
              "      <td>person</td>\n",
              "      <td>145</td>\n",
              "      <td>118</td>\n",
              "      <td>229</td>\n",
              "      <td>333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>004574_jpg.rf.7c8cea69d7be45f58febcede26ef0c6e...</td>\n",
              "      <td>500</td>\n",
              "      <td>333</td>\n",
              "      <td>person</td>\n",
              "      <td>285</td>\n",
              "      <td>105</td>\n",
              "      <td>349</td>\n",
              "      <td>329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100077</th>\n",
              "      <td>2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...</td>\n",
              "      <td>4410</td>\n",
              "      <td>3308</td>\n",
              "      <td>person</td>\n",
              "      <td>1957</td>\n",
              "      <td>1753</td>\n",
              "      <td>2022</td>\n",
              "      <td>1847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100078</th>\n",
              "      <td>2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...</td>\n",
              "      <td>4410</td>\n",
              "      <td>3308</td>\n",
              "      <td>person</td>\n",
              "      <td>2014</td>\n",
              "      <td>1753</td>\n",
              "      <td>2099</td>\n",
              "      <td>1854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100079</th>\n",
              "      <td>2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...</td>\n",
              "      <td>4410</td>\n",
              "      <td>3308</td>\n",
              "      <td>person</td>\n",
              "      <td>1519</td>\n",
              "      <td>1805</td>\n",
              "      <td>1588</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100080</th>\n",
              "      <td>2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...</td>\n",
              "      <td>4410</td>\n",
              "      <td>3308</td>\n",
              "      <td>person</td>\n",
              "      <td>1588</td>\n",
              "      <td>1809</td>\n",
              "      <td>1657</td>\n",
              "      <td>1901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100081</th>\n",
              "      <td>2008_007145_jpg.rf.99fc120cdee10b38fe50fe80989...</td>\n",
              "      <td>4410</td>\n",
              "      <td>3308</td>\n",
              "      <td>person</td>\n",
              "      <td>1464</td>\n",
              "      <td>1753</td>\n",
              "      <td>1529</td>\n",
              "      <td>1870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100082 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e32a119-3e62-4875-9c22-c6593fe97b29')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e32a119-3e62-4875-9c22-c6593fe97b29 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e32a119-3e62-4875-9c22-c6593fe97b29');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_674406ab-9b03-44d4-87ab-a4e001e68025\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_674406ab-9b03-44d4-87ab-a4e001e68025 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms as T\n",
        "\n",
        "class PeopleDetectionDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_dir, transform=None):\n",
        "        self.df = dataframe\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.images = dataframe['filename'].unique().tolist()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.images[idx]\n",
        "\n",
        "        img_path = os.path.join(self.image_dir, filename)\n",
        "        if not os.path.exists(img_path):\n",
        "            raise FileNotFoundError(f\"Image file {img_path} not found!\")\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "\n",
        "        boxes_df = self.df[self.df['filename'] == filename]\n",
        "        boxes = boxes_df[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "\n",
        "\n",
        "        w = boxes[:, 2] - boxes[:, 0]\n",
        "        h = boxes[:, 3] - boxes[:, 1]\n",
        "        x_center = boxes[:, 0] + w / 2\n",
        "        y_center = boxes[:, 1] + h / 2\n",
        "\n",
        "        img_w, img_h = image.size\n",
        "        x_center /= img_w\n",
        "        y_center /= img_h\n",
        "        w /= img_w\n",
        "        h /= img_h\n",
        "\n",
        "        boxes = torch.stack([x_center, y_center, w, h], dim=1)\n",
        "\n",
        "\n",
        "        labels = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'image_id': torch.tensor([idx])\n",
        "        }\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n"
      ],
      "metadata": {
        "id": "ShvMjZdk1IE0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize((360, 360)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "PpXvMWfo1oxz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = PeopleDetectionDataset(df,path+'/train/train',transform)"
      ],
      "metadata": {
        "id": "-oMTjmTB1LoT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaded = torch.utils.data.DataLoader(datasets,batch_size=32,shuffle=True,collate_fn=lambda x : tuple(zip(*x)))"
      ],
      "metadata": {
        "id": "peGGN9NG13S_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pooling_data (target_data) :\n",
        "  boxes = []\n",
        "  label = []\n",
        "  for t in target_data :\n",
        "    boxes.append(t['boxes'].to('cuda'))\n",
        "    label.append(t['labels'].to('cuda'))\n",
        "  return boxes,label"
      ],
      "metadata": {
        "id": "GDicTOhu2Bzz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = DETR(image_size=360,embed_dim=384,num_query=100,num_class=1)\n",
        "optimizer = torch.optim.AdamW(pretrained_model.parameters(),lr=0.0001)\n",
        "pretrained_model.to('cuda')\n",
        "pretrained_model.train()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaHx9vLl_LG5",
        "outputId": "c2140f37-00d6-41f1-8890-ee86316d72bb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DETR(\n",
              "  (backbone): VIT(\n",
              "    (patchembedding): PatchEmbedding(\n",
              "      (projection): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
              "    )\n",
              "    (postionalencoder): PositionalEncoding()\n",
              "    (Transformersblock): ModuleList(\n",
              "      (0-2): 3 x VITBlock(\n",
              "        (norm): ScaleNorm()\n",
              "        (dropout): Dropout(p=0.05, inplace=False)\n",
              "        (attention): GatingAttentionUnit(\n",
              "          (lq): Linear(in_features=384, out_features=384, bias=False)\n",
              "          (lk): Linear(in_features=384, out_features=384, bias=False)\n",
              "          (lv): Linear(in_features=384, out_features=384, bias=False)\n",
              "          (lgate): Linear(in_features=384, out_features=384, bias=True)\n",
              "          (lo): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (lcm): LCM(\n",
              "          (norm): ScaleNorm()\n",
              "          (dropout): Dropout(p=0.05, inplace=False)\n",
              "          (step1): Linear(in_features=384, out_features=384, bias=True)\n",
              "          (step2): Linear(in_features=384, out_features=384, bias=True)\n",
              "          (magnitude): Linear(in_features=384, out_features=384, bias=True)\n",
              "          (rezero): ReZero()\n",
              "        )\n",
              "        (rezero): ReZero()\n",
              "      )\n",
              "    )\n",
              "    (globalffn): Sequential(\n",
              "      (0): Linear(in_features=384, out_features=1152, bias=True)\n",
              "      (1): GELU(approximate='none')\n",
              "      (2): Linear(in_features=1152, out_features=384, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (Decoderblock): ModuleList(\n",
              "      (0-2): 3 x DecoderBlock(\n",
              "        (norm1): RMSNorm((384,), eps=None, elementwise_affine=True)\n",
              "        (norm2): RMSNorm((384,), eps=None, elementwise_affine=True)\n",
              "        (norm3): RMSNorm((384,), eps=None, elementwise_affine=True)\n",
              "        (attention): MultiQueryAttention(\n",
              "          (lq): Linear(in_features=384, out_features=384, bias=False)\n",
              "          (lk): Linear(in_features=384, out_features=96, bias=False)\n",
              "          (lv): Linear(in_features=384, out_features=96, bias=False)\n",
              "          (lo): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (siglu): SiGLU(\n",
              "          (l1): Linear(in_features=384, out_features=768, bias=True)\n",
              "          (l2): Linear(in_features=384, out_features=768, bias=True)\n",
              "          (l3): Linear(in_features=768, out_features=384, bias=True)\n",
              "        )\n",
              "        (crossAttention): MultiQueryAttention(\n",
              "          (lq): Linear(in_features=384, out_features=384, bias=False)\n",
              "          (lk): Linear(in_features=384, out_features=96, bias=False)\n",
              "          (lv): Linear(in_features=384, out_features=96, bias=False)\n",
              "          (lo): Linear(in_features=384, out_features=384, bias=True)\n",
              "        )\n",
              "        (dropou1): Dropout(p=0.1, inplace=False)\n",
              "        (dropou2): Dropout(p=0.1, inplace=False)\n",
              "        (dropou3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (class_head): Linear(in_features=384, out_features=2, bias=True)\n",
              "  (box_head): Sequential(\n",
              "    (0): Linear(in_features=384, out_features=384, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=384, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_hits = []\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "O3bgHVeB-7uh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 2\n",
        "for epoch in range(epochs) :\n",
        "  loss_total = 0\n",
        "  iterator = tqdm(dataloaded)\n",
        "  for image,label in iterator :\n",
        "    image = torch.stack(image,dim=0).to('cuda')\n",
        "    label = pooling_data(label)\n",
        "    predicted = pretrained_model(image)\n",
        "    loss = detr_loss(predicted['class_pred'],predicted['box_pred'],label[1],label[0],1)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_total += loss.item()\n",
        "    iterator.set_description(f\"epoch {epoch+1}/{epochs} loss : {loss.item()}\")\n",
        "\n",
        "  loss_total /= len(dataloaded)\n",
        "  loss_hits.append(loss_total)\n",
        "  print(f\"epoch {epoch+1}/{epochs} loss : {loss_total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jqc8Ik7p_6C5",
        "outputId": "7c531ecf-6c56-4311-d47f-ada532cb4505"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1/2 loss : 9.4094877243042: 100%|██████████| 415/415 [07:23<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/2 loss : 10.068002064256783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2/2 loss : 9.930267333984375: 100%|██████████| 415/415 [07:28<00:00,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2/2 loss : 9.941144192936909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_hits)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "wtf_2QHgm6ly",
        "outputId": "d216bb36-f7cf-4ede-83a3-a2e3e18e3277"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Note :  is just experiment, gating Attention units and Multi Query units is  present for NLP model and fokus at spesial token contexts. if you wanna make a real DETR, you can use this note book, but just replace a GAU and MQA to MHA ."
      ],
      "metadata": {
        "id": "dVD9lEAqnPxg"
      }
    }
  ]
}